{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Lambda, MaxPooling1D, Conv1D, Flatten, LSTM\n",
    "import keras.backend as K\n",
    "from keras.models import Model,Sequential\n",
    "from keras.regularizers import l2\n",
    "from keras import Input\n",
    "\n",
    "#from keras.layers import Input, Conv2D, Lambda, merge, Dense, Flatten,MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(513, 32)\n",
      "(500, 513, 32)\n",
      "200\n",
      "(200, 513, 45)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "with open('hw4_trs.pkl', 'rb') as f:\n",
    "    data_train = pickle.load(f)\n",
    "    \n",
    "    \n",
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "\n",
    "train_data=[]\n",
    "\n",
    "for i in range(500):\n",
    "    S=librosa.stft(data_train[i], n_fft=1024, hop_length=512)\n",
    "    train_data.append(S)\n",
    "print(S.shape)\n",
    "train_data=np.stack(train_data)\n",
    "print(train_data.shape)\n",
    "\n",
    "test_data=[]\n",
    "with open('hw4_tes.pkl', 'rb') as f1:\n",
    "    data_test = pickle.load(f1)\n",
    "\n",
    "    \n",
    "for i in range(200):\n",
    "    S=librosa.stft(data_test[i], n_fft=1024, hop_length=512)\n",
    "    test_data.append(S)\n",
    "print(len(test_data))\n",
    "\n",
    "test_data=np.stack(test_data)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 32, 513)\n"
     ]
    }
   ],
   "source": [
    "train_data=np.abs(train_data).transpose((0,2,1))\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 45, 513)\n"
     ]
    }
   ],
   "source": [
    "test_data=np.abs(test_data).transpose((0,2,1))\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 45, 2, 32, 513)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(l).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Siamese Network\n",
    "# Define the tensors for the two input speech signals\n",
    "first_In = Input(shape=(None,513))\n",
    "second_In = Input(shape=(None,513))\n",
    "    \n",
    "# Convolutional Neural Network\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=32, kernel_size=2,activation='relu',strides=1, padding='same',input_shape=(None,513),kernel_initializer='he_normal'))\n",
    "model.add(MaxPooling1D(pool_size=2,strides=1, padding='valid'))\n",
    "model.add(Conv1D(filters=32, kernel_size=2,activation='relu',strides=1, padding='same',kernel_initializer='he_normal'))\n",
    "model.add(MaxPooling1D(pool_size=2,strides=1, padding='valid'))\n",
    "model.add(Conv1D(filters=16, kernel_size=3,activation='relu',strides=1, padding='same',kernel_initializer='he_normal'))\n",
    "model.add(MaxPooling1D(pool_size=2,strides=1, padding='valid'))\n",
    "model.add(Conv1D(filters=32, kernel_size=2, activation='relu', kernel_initializer='he_normal' ))\n",
    "model.add(LSTM(350))\n",
    "    \n",
    "# Generate the encodings (feature vectors) for the two speech signals\n",
    "encoded_1 = model(first_In)\n",
    "encoded_2 = model(second_In)\n",
    "    \n",
    " # Add a customized layer to compute the absolute difference between the encodings\n",
    "L1_layer = Lambda(lambda tensors:K.sum(tensors[0]*tensors[1],axis=-1,keepdims=True)) \n",
    "L1_dot = L1_layer([encoded_1, encoded_2])\n",
    "    \n",
    "    # Add a dense layer with a sigmoid unit to generate the similarity score\n",
    "prediction = Dense(1,activation='sigmoid')(L1_dot)\n",
    "    \n",
    "    # Connect the inputs with the outputs\n",
    "siamese_net = Model(inputs=[first_In,second_In],outputs=prediction)\n",
    "    \n",
    "    # return the model\n",
    "siamese_net.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating batches of samples of data\n",
    "from itertools import combinations\n",
    "import random\n",
    "import itertools\n",
    "def generator(train_data):\n",
    "    train_data=np.abs(train_data).transpose((0,2,1))\n",
    "    while True:\n",
    "        for i in range(0,510,10):\n",
    "            if i>=len(train_data)-10:\n",
    "                i=0\n",
    "            p=np.array(list(combinations(train_data[i:i+10],2)))\n",
    "            negative_1=list(itertools.product(train_data[i:i+10],train_data[i+10:500]))\n",
    "            negative_1=random.sample(negative_1,45)\n",
    "            negative_1=np.array(negative_1)\n",
    "            data_List=np.concatenate([p, negative_1])\n",
    "            label=[]\n",
    "            for i in range(45): \n",
    "                \n",
    "                label.append(1)\n",
    "            for i in range(45):\n",
    "                label.append(0)\n",
    "        \n",
    "            c = list(zip(data_List, label))\n",
    "            random.shuffle(c)\n",
    "            data_List, label = zip(*c)\n",
    "            data_List=np.array(data_List)\n",
    "            label=np.array(label)\n",
    "            data_List=data_List.transpose((1,0,2,3))\n",
    "\n",
    "            yield [data_List[0],data_List[1]], label[:90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating batches of samples of data\n",
    "from itertools import combinations\n",
    "import random\n",
    "import itertools\n",
    "def generator1(test_data):\n",
    "    test_data=np.abs(test_data).transpose((0,2,1))\n",
    "    while True:\n",
    "        for i in range(0,210,10):\n",
    "            if i>=len(test_data)-10:\n",
    "                i=0\n",
    "            p1=np.array(list(combinations(test_data[i:i+10],2)))\n",
    "            negative_2=list(itertools.product(test_data[i:i+10],test_data[i+10:200]))\n",
    "            negative_2=random.sample(negative_2,45)\n",
    "            negative_2=np.array(negative_2)\n",
    "            data_List1=np.concatenate([p1, negative_2])\n",
    "            label1=[]\n",
    "            for i in range(45):\n",
    "                label1.append(1)\n",
    "            for i in range(45):\n",
    "                 label1.append(0)\n",
    "        \n",
    "            c1 = list(zip(data_List1, label1))\n",
    "            random.shuffle(c1)\n",
    "            data_List1, label1 = zip(*c1)\n",
    "            data_List1=np.array(data_List1)\n",
    "            label1=np.array(label1)\n",
    "            data_List1=data_List1.transpose((1,0,2,3))\n",
    "\n",
    "            yield [data_List1[0],data_List1[1]], label1[:90]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "50/50 [==============================] - 23s 467ms/step - loss: 0.8356 - acc: 0.5064\n",
      "Epoch 2/50\n",
      "50/50 [==============================] - 21s 425ms/step - loss: 0.6875 - acc: 0.5500\n",
      "Epoch 3/50\n",
      "50/50 [==============================] - 22s 440ms/step - loss: 0.6763 - acc: 0.6093\n",
      "Epoch 4/50\n",
      "50/50 [==============================] - 22s 447ms/step - loss: 0.6790 - acc: 0.6067\n",
      "Epoch 5/50\n",
      "50/50 [==============================] - 22s 442ms/step - loss: 0.6688 - acc: 0.6013\n",
      "Epoch 6/50\n",
      "50/50 [==============================] - 22s 447ms/step - loss: 0.6580 - acc: 0.6153\n",
      "Epoch 7/50\n",
      "50/50 [==============================] - 22s 439ms/step - loss: 0.7312 - acc: 0.6147\n",
      "Epoch 8/50\n",
      "50/50 [==============================] - 22s 440ms/step - loss: 0.6424 - acc: 0.6082\n",
      "Epoch 9/50\n",
      "50/50 [==============================] - 22s 442ms/step - loss: 0.6167 - acc: 0.6373\n",
      "Epoch 10/50\n",
      "50/50 [==============================] - 22s 441ms/step - loss: 0.6049 - acc: 0.6602\n",
      "Epoch 11/50\n",
      "50/50 [==============================] - 22s 440ms/step - loss: 0.5917 - acc: 0.6887\n",
      "Epoch 12/50\n",
      "50/50 [==============================] - 22s 439ms/step - loss: 0.5669 - acc: 0.7149\n",
      "Epoch 13/50\n",
      "50/50 [==============================] - 22s 443ms/step - loss: 0.5569 - acc: 0.7316\n",
      "Epoch 14/50\n",
      "50/50 [==============================] - 22s 440ms/step - loss: 0.5551 - acc: 0.7256\n",
      "Epoch 15/50\n",
      "50/50 [==============================] - 23s 452ms/step - loss: 0.5322 - acc: 0.7500\n",
      "Epoch 16/50\n",
      "50/50 [==============================] - 22s 441ms/step - loss: 0.5066 - acc: 0.7822\n",
      "Epoch 17/50\n",
      "50/50 [==============================] - 23s 464ms/step - loss: 0.4995 - acc: 0.7847\n",
      "Epoch 18/50\n",
      "50/50 [==============================] - 22s 439ms/step - loss: 0.4873 - acc: 0.7809\n",
      "Epoch 19/50\n",
      "50/50 [==============================] - 22s 438ms/step - loss: 0.4943 - acc: 0.7798\n",
      "Epoch 20/50\n",
      "50/50 [==============================] - 22s 441ms/step - loss: 0.4680 - acc: 0.8042\n",
      "Epoch 21/50\n",
      "50/50 [==============================] - 22s 438ms/step - loss: 0.4577 - acc: 0.8036\n",
      "Epoch 22/50\n",
      "50/50 [==============================] - 23s 458ms/step - loss: 0.5118 - acc: 0.7587\n",
      "Epoch 23/50\n",
      "50/50 [==============================] - 22s 440ms/step - loss: 0.4810 - acc: 0.7867\n",
      "Epoch 24/50\n",
      "50/50 [==============================] - 22s 438ms/step - loss: 0.4672 - acc: 0.7916\n",
      "Epoch 25/50\n",
      "50/50 [==============================] - 22s 440ms/step - loss: 0.4527 - acc: 0.8067\n",
      "Epoch 26/50\n",
      "50/50 [==============================] - 22s 439ms/step - loss: 0.4415 - acc: 0.8136\n",
      "Epoch 27/50\n",
      "50/50 [==============================] - 22s 438ms/step - loss: 0.4402 - acc: 0.8153\n",
      "Epoch 28/50\n",
      "50/50 [==============================] - 22s 439ms/step - loss: 0.4076 - acc: 0.8293\n",
      "Epoch 29/50\n",
      "50/50 [==============================] - 22s 440ms/step - loss: 0.4200 - acc: 0.8356\n",
      "Epoch 30/50\n",
      "50/50 [==============================] - 22s 437ms/step - loss: 0.4352 - acc: 0.8187\n",
      "Epoch 31/50\n",
      "50/50 [==============================] - 22s 437ms/step - loss: 0.4249 - acc: 0.8180\n",
      "Epoch 32/50\n",
      "50/50 [==============================] - 22s 438ms/step - loss: 0.3986 - acc: 0.8396\n",
      "Epoch 33/50\n",
      "50/50 [==============================] - 22s 440ms/step - loss: 0.3985 - acc: 0.8458\n",
      "Epoch 34/50\n",
      "50/50 [==============================] - 23s 453ms/step - loss: 0.4045 - acc: 0.8398\n",
      "Epoch 35/50\n",
      "50/50 [==============================] - 22s 439ms/step - loss: 0.3943 - acc: 0.8416\n",
      "Epoch 36/50\n",
      "50/50 [==============================] - 22s 443ms/step - loss: 0.3739 - acc: 0.8533\n",
      "Epoch 37/50\n",
      "50/50 [==============================] - 22s 441ms/step - loss: 0.3804 - acc: 0.8504\n",
      "Epoch 38/50\n",
      "50/50 [==============================] - 22s 437ms/step - loss: 0.3704 - acc: 0.8551\n",
      "Epoch 39/50\n",
      "50/50 [==============================] - 22s 440ms/step - loss: 0.3570 - acc: 0.8656\n",
      "Epoch 40/50\n",
      "50/50 [==============================] - 22s 436ms/step - loss: 0.4153 - acc: 0.8300\n",
      "Epoch 41/50\n",
      "50/50 [==============================] - 22s 438ms/step - loss: 0.4217 - acc: 0.8236\n",
      "Epoch 42/50\n",
      "50/50 [==============================] - 22s 440ms/step - loss: 0.3653 - acc: 0.8551\n",
      "Epoch 43/50\n",
      "50/50 [==============================] - 22s 440ms/step - loss: 0.3552 - acc: 0.8616\n",
      "Epoch 44/50\n",
      "50/50 [==============================] - 22s 442ms/step - loss: 0.3485 - acc: 0.8653\n",
      "Epoch 45/50\n",
      "50/50 [==============================] - 22s 443ms/step - loss: 0.3738 - acc: 0.8567\n",
      "Epoch 46/50\n",
      "50/50 [==============================] - 22s 444ms/step - loss: 0.3499 - acc: 0.8631\n",
      "Epoch 47/50\n",
      "50/50 [==============================] - 23s 454ms/step - loss: 0.3436 - acc: 0.8693\n",
      "Epoch 48/50\n",
      "50/50 [==============================] - 23s 470ms/step - loss: 0.3356 - acc: 0.8707\n",
      "Epoch 49/50\n",
      "50/50 [==============================] - 23s 454ms/step - loss: 0.3173 - acc: 0.8789\n",
      "Epoch 50/50\n",
      "50/50 [==============================] - 22s 447ms/step - loss: 0.3234 - acc: 0.8822\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d16476af60>"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training model\n",
    "siamese_net.fit_generator(generator(train_data.transpose((0,2,1))),steps_per_epoch = len(train_data)/10, epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4929323211312294, 0.7666666716337204]"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "siamese_net.evaluate_generator(generator1(test_data.transpose((0,2,1))),steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_net.evaluate_generator(generator1(test_data.transpose((0,2,1))),steps=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
